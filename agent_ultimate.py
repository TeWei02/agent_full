import os
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.ollama import Ollama
from llama_index.llms.groq import Groq
from llama_index.core.embeddings import resolve_embed_model

print("ğŸš€ ModernReader çµ‚æ¥µå…è²» AI Agent å•Ÿå‹•ä¸­...\n")

# ============ é…ç½®é¸é … ============
USE_GROQ = True  # True = ä½¿ç”¨ Groqï¼ˆå¿«ï¼‰ï¼ŒFalse = ä½¿ç”¨ Ollamaï¼ˆæœ¬åœ°ï¼‰
GROQ_API_KEY = os.getenv("GROQ_API_KEY")  # å¡«å…¥ä½ çš„ Groq Key

# ============ è¨­å®š LLM ============
if USE_GROQ:
    print("ğŸŒ ä½¿ç”¨ Groq é›²ç«¯ APIï¼ˆé€Ÿåº¦å¿«ï¼‰...")
    os.environ["GROQ_API_KEY"] = GROQ_API_KEY
    llm = Groq(
        model="llama-3.1-70b-versatile",  # æˆ– "llama-3.3-70b-versatile"
        api_key=GROQ_API_KEY
    )
    Settings.llm = llm
    print("âœ… Groq LLM å·²é€£æ¥\n")
else:
    print("ğŸ–¥ï¸  ä½¿ç”¨æœ¬åœ° Ollamaï¼ˆå®Œå…¨å…è²»ï¼‰...")
    llm = Ollama(
        model="llama3.2:3b",  # æˆ– "qwen2.5:7b"
        request_timeout=120.0
    )
    Settings.llm = llm
    print("âœ… Ollama å·²é€£æ¥\n")

# ============ è¨­å®š Embeddingï¼ˆæœ¬åœ°å…è²»ï¼‰============
print("ğŸ“Š è¼‰å…¥æœ¬åœ° Embedding æ¨¡å‹...")
Settings.embed_model = resolve_embed_model("local:BAAI/bge-small-en-v1.5")
print("âœ… Embedding å·²æº–å‚™\n")

# ============ è¼‰å…¥ PDF ============
print("ğŸ“„ è¼‰å…¥ PDF æ–‡ä»¶...")
try:
    documents = SimpleDirectoryReader(
        input_files=["sample.pdf"]
    ).load_data()
    print(f"âœ… æˆåŠŸè¼‰å…¥ {len(documents)} å€‹æ–‡ä»¶")
    print(f"   ç¸½å­—æ•¸: {sum(len(doc.text) for doc in documents)} å­—\n")
except Exception as e:
    print(f"âŒ è¼‰å…¥å¤±æ•—: {e}\n")
    exit(1)

# ============ å»ºç«‹å‘é‡ç´¢å¼• ============
print("ğŸ” å»ºç«‹å‘é‡ç´¢å¼•ï¼ˆé€™å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“ï¼‰...")
try:
    index = VectorStoreIndex.from_documents(documents, show_progress=True)
    print("âœ… ç´¢å¼•å»ºç«‹å®Œæˆ\n")
except Exception as e:
    print(f"âŒ ç´¢å¼•å»ºç«‹å¤±æ•—: {e}\n")
    exit(1)

# ============ å»ºç«‹æŸ¥è©¢å¼•æ“ ============
print("âš™ï¸  è¨­ç½®æŸ¥è©¢å¼•æ“...")
query_engine = index.as_query_engine(
    similarity_top_k=3,
    streaming=False
)
print("âœ… æŸ¥è©¢å¼•æ“å·²æº–å‚™\n")

# ============ è‡ªå‹•æ¸¬è©¦ ============
print("="*60)
print("ğŸ¯ AI Agent å·²æº–å‚™å¥½ï¼é–‹å§‹è‡ªå‹•æ¸¬è©¦")
print("="*60 + "\n")

test_queries = [
    "é€™å€‹æ–‡ä»¶ä¸»è¦è¬›ä»€éº¼ï¼Ÿè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”",
    "æ–‡ä»¶ä¸­æåˆ°å“ªäº›æŠ€è¡“ï¼Ÿ",
    "ModernReader ç³»çµ±çš„æ ¸å¿ƒçµ„ä»¶æ˜¯ä»€éº¼ï¼Ÿ"
]

for i, query in enumerate(test_queries, 1):
    print(f"ğŸ“ æ¸¬è©¦ {i}/{len(test_queries)}: {query}")
    try:
        response = query_engine.query(query)
        print(f"ğŸ¤– å›ç­”: {response}\n")
    except Exception as e:
        print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}\n")

# ============ äº’å‹•æ¨¡å¼ ============
print("="*60)
print("ğŸ’¬ é€²å…¥äº’å‹•æ¨¡å¼")
print("="*60)
print("æŒ‡ä»¤:")
print("  - è¼¸å…¥å•é¡Œï¼šç›´æ¥æå•")
print("  - 'switch': åˆ‡æ› LLMï¼ˆGroq â†” Ollamaï¼‰")
print("  - 'info': é¡¯ç¤ºç•¶å‰é…ç½®")
print("  - 'exit': é€€å‡º\n")

while True:
    try:
        user_input = input("ä½ : ").strip()
        
        if not user_input:
            continue
            
        if user_input.lower() in ['exit', 'quit', 'q']:
            print("\nğŸ‘‹ æ„Ÿè¬ä½¿ç”¨ ModernReader AI Agentï¼å†è¦‹~")
            break
        
        if user_input.lower() == 'switch':
            USE_GROQ = not USE_GROQ
            if USE_GROQ:
                Settings.llm = Groq(model="llama-3.1-70b-versatile", api_key=GROQ_API_KEY)
                print("âœ… å·²åˆ‡æ›åˆ° Groqï¼ˆé›²ç«¯ï¼‰\n")
            else:
                Settings.llm = Ollama(model="llama3.2:3b", request_timeout=120.0)
                print("âœ… å·²åˆ‡æ›åˆ° Ollamaï¼ˆæœ¬åœ°ï¼‰\n")
            query_engine = index.as_query_engine(similarity_top_k=3)
            continue
        
        if user_input.lower() == 'info':
            llm_type = "Groq (é›²ç«¯)" if USE_GROQ else "Ollama (æœ¬åœ°)"
            print(f"\nğŸ“Š ç•¶å‰é…ç½®:")
            print(f"   LLM: {llm_type}")
            print(f"   æ–‡ä»¶æ•¸: {len(documents)}")
            print(f"   Embedding: BAAI/bge-small-en-v1.5 (æœ¬åœ°)\n")
            continue
        
        # æ­£å¸¸æŸ¥è©¢
        print("ğŸ¤– æ€è€ƒä¸­...\n")
        response = query_engine.query(user_input)
        print(f"å›ç­”: {response}\n")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ å·²ä¸­æ–·ï¼Œå†è¦‹ï¼")
        break
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}\n")
        print("æç¤º: å¦‚æœæ˜¯ Groq API éŒ¯èª¤ï¼Œè©¦è©¦è¼¸å…¥ 'switch' åˆ‡æ›åˆ° Ollama\n")

