import os
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.core.tools import QueryEngineTool, ToolMetadata, FunctionTool
from llama_index.core.agent import ReActAgent
from llama_index.llms.ollama import Ollama
from llama_index.embeddings.ollama import OllamaEmbedding
import datetime

print("ğŸ¤– ModernReader AI Agent å•Ÿå‹•ä¸­...\n")

CURRENT_MODEL = "llama3:latest"
llm = Ollama(model=CURRENT_MODEL, request_timeout=300.0)
Settings.llm = llm
Settings.embed_model = OllamaEmbedding(model_name=CURRENT_MODEL)

documents = SimpleDirectoryReader(input_files=["sample.pdf"]).load_data()
index = VectorStoreIndex.from_documents(documents, show_progress=True)
query_engine = index.as_query_engine(similarity_top_k=3)

pdf_tool = QueryEngineTool(query_engine=query_engine, metadata=ToolMetadata(name="search_pdf", description="æœå°‹PDF"))

def calculate(expression: str) -> str:
    try: return f"{expression} = {eval(expression)}"
    except Exception as e: return f"éŒ¯èª¤: {e}"

def get_time() -> str:
    return datetime.datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')

def get_stats() -> str:
    return f"æ–‡ä»¶æ•¸: {len(documents)}, å­—æ•¸: {sum(len(d.text.split()) for d in documents):,}"

calculator_tool = FunctionTool.from_defaults(fn=calculate, name="calc", description="è¨ˆç®—")
time_tool = FunctionTool.from_defaults(fn=get_time, name="time", description="æ™‚é–“")
stats_tool = FunctionTool.from_defaults(fn=get_stats, name="stats", description="çµ±è¨ˆ")

tools = [pdf_tool, calculator_tool, time_tool, stats_tool]
agent = ReActAgent(name="Agent", tools=tools, llm=llm, verbose=True)

print("âœ… Agent å·²å•Ÿå‹•\n")

tests = ["ç¾åœ¨å¹¾é»ï¼Ÿ", "è¨ˆç®— 10+20", "æ–‡ä»¶çµ±è¨ˆ", "PDFè¬›ä»€éº¼ï¼Ÿ"]
for test in tests:
    print(f"\nQ: {test}")
    print(f"A: {agent.chat(test).response}\n")

print("\nğŸ’¬ äº’å‹•æ¨¡å¼ (exité€€å‡º)\n")
while True:
    q = input("ä½ : ").strip()
    if q.lower() in ['exit', 'quit']: break
    if q: print(f"\nğŸ¤– {agent.chat(q).response}\n")
